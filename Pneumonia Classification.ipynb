{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying Pneumonia Patients based on X-Ray Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deanna Gould**  \n",
    "Phase 4 Flex Student  \n",
    "Instructor: Morgan Jones  \n",
    "Presentation Date: September 27, 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HealthWorx is a telehealth company that would like to be able to diagnose patients with pneumonia from an X-Ray. X-Ray images can be taken in several locations, and this could decrease wait times for patients. Based on the [CDC Website](https://www.cdc.gov/nchs/fastats/pneumonia.htm), 41,309 people die from pneumonia each year, and 1.5 million people visit the emergency room with pneumonia as the primary diagnosis. Emergency rooms are known for their long wait times and becoming overcrowded, so this could also improve other patient's experiences. Pneumonia can have long-lasting effects on the health and well-being of patients. This jupyter notebook will take steps to predict whether a patient has pneumonia or not by using neural networks and image classification of X-Ray images. Although this wouldn't be able to completely replace a doctor's part in diagnosing the patient, this could be used as an added precaution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset consists of 4,818 images for train data, 418 images for test data, and 624 images for validation data. Different algorithms like  will be used and each model will be tuned to determine the best model. Binary cross-entropy will be used as the loss function because this is a binary classification problem. For evaluation metrics, accuracy score, recall, and precision will be considered, but recall will be most important because pneumonia is a health-risk. Recall is the number of true positives divided by the number of true positives and false negatives. A false negative can be detrimental in healthcare settings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'float'.\n`np.float` was a deprecated alias for the builtin `float`. To avoid this error in existing code, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 14\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (plot_confusion_matrix, confusion_matrix, classification_report, roc_curve, auc, \n\u001b[1;32m     11\u001b[0m                              RocCurveDisplay)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlime\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m lime_base\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m lime_image\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/lime/lime_base.py:6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msp\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Ridge, lars_path\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_random_state\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mLimeBase\u001b[39;00m(\u001b[38;5;28mobject\u001b[39m):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/linear_model/__init__.py:11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_base\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LinearRegression\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_bayes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BayesianRidge, ARDRegression\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_least_angle\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (Lars, LassoLars, lars_path, lars_path_gram, LarsCV,\n\u001b[1;32m     12\u001b[0m                            LassoLarsCV, LassoLarsIC)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_coordinate_descent\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (Lasso, ElasticNet, LassoCV, ElasticNetCV,\n\u001b[1;32m     14\u001b[0m                                   lasso_path, enet_path, MultiTaskLasso,\n\u001b[1;32m     15\u001b[0m                                   MultiTaskElasticNet, MultiTaskElasticNetCV,\n\u001b[1;32m     16\u001b[0m                                   MultiTaskLassoCV)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_glm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (PoissonRegressor,\n\u001b[1;32m     18\u001b[0m                    GammaRegressor, TweedieRegressor)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:34\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvalidation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _deprecate_positional_args\n\u001b[1;32m     29\u001b[0m SOLVE_TRIANGULAR_ARGS \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcheck_finite\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m}\n\u001b[1;32m     32\u001b[0m \u001b[38;5;129m@_deprecate_positional_args\u001b[39m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlars_path\u001b[39m(X, y, Xy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, Gram\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m, alpha_min\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m---> 34\u001b[0m               method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlar\u001b[39m\u001b[38;5;124m'\u001b[39m, copy_X\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, eps\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfinfo(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m)\u001b[38;5;241m.\u001b[39meps,\n\u001b[1;32m     35\u001b[0m               copy_Gram\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, return_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     36\u001b[0m               return_n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, positive\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;124;03m\"\"\"Compute Least Angle Regression or Lasso path using LARS algorithm [1]\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \n\u001b[1;32m     39\u001b[0m \u001b[38;5;124;03m    The optimization objective for the case method='lasso' is::\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    148\u001b[0m \n\u001b[1;32m    149\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m Gram \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/numpy/__init__.py:305\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    300\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    301\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn the future `np.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` will be defined as the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    302\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcorresponding NumPy scalar.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m __former_attrs__:\n\u001b[0;32m--> 305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(__former_attrs__[attr])\n\u001b[1;32m    307\u001b[0m \u001b[38;5;66;03m# Importing Tester requires importing all of UnitTest which is not a\u001b[39;00m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;66;03m# cheap import Since it is mainly used in test suits, we lazy import it\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;66;03m# here to save on the order of 10 ms of import time for most users\u001b[39;00m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;66;03m# The previous way Tester was imported also had a side effect of adding\u001b[39;00m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;66;03m# the full `numpy.testing` namespace\u001b[39;00m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtesting\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'float'.\n`np.float` was a deprecated alias for the builtin `float`. To avoid this error in existing code, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"
     ]
    }
   ],
   "source": [
    "# Importing libraries\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (plot_confusion_matrix, confusion_matrix, classification_report, roc_curve, auc, \n",
    "                             RocCurveDisplay)\n",
    "\n",
    "import lime\n",
    "from lime import lime_base\n",
    "from lime import lime_image\n",
    "import tensorflow as tf\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function called plot history\n",
    "\n",
    "def plot_history(history):\n",
    "    acc = history.history['binary_accuracy']\n",
    "    val_acc = history.history['val_binary_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(len(acc))\n",
    "    plt.plot(epochs, acc, 'pink', label='Training accuracy')\n",
    "    plt.plot(epochs, val_acc, 'blue', label='Validation accuracy')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()\n",
    "    plt.figure()\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function for rocauc\n",
    "# Plot will have true positives on y and false positive values on X, with the ROC line being curved, and the AUC \n",
    "# being a straight line.\n",
    "\n",
    "def plot_roc_auc(y_true, y_score):\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_score)\n",
    "\n",
    "    print('AUC: {}'.format(auc(fpr, tpr)))\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    lw = 2\n",
    "    plt.plot(fpr, tpr, color='blue',\n",
    "         lw=lw, label='ROC curve')\n",
    "    plt.plot([0, 1], [0, 1], color='pink', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.yticks([i/20.0 for i in range(21)])\n",
    "    plt.xticks([i/20.0 for i in range(21)])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic (ROC) Curve')\n",
    "    plt.legend(loc='lower right');\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function\n",
    "\n",
    "# Code below from stack overflow\n",
    "# https://stackoverflow.com/questions/45413712/keras-get-true-labels-y-test-from-imagedatagenerator-or-predict%20%20%20%20%20-generator/67282636#67282636\n",
    "\n",
    "def pred_labels(model, generator):\n",
    "\n",
    "# Create lists for storing the predictions and labels\n",
    "# Labels in this case are actual values and predictions are predicted values\n",
    "    predictions = []\n",
    "    labels = []\n",
    "\n",
    "# Get the total number of labels in generator \n",
    "# (i.e. the length of the dataset where the generator generates batches from)\n",
    "    n = len(generator.labels)\n",
    "\n",
    "# Loop over the generator\n",
    "    for data, label in generator:\n",
    "    # Make predictions on data using the model. Store the results.\n",
    "        predictions.extend(model.predict(data, workers = 4).flatten())\n",
    "\n",
    "    # Store corresponding labels\n",
    "        labels.extend(label)\n",
    "\n",
    "    # We have to break out from the generator when we've processed \n",
    "    # the entire once (otherwise we would end up with duplicates). \n",
    "        if (len(label) < generator.batch_size) and (len(predictions) == n):\n",
    "            break\n",
    "    return labels, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a function to plot \n",
    "def conf_matrix(y_true, y_pred):\n",
    "\n",
    "    #Converting probabilities to 0 and 1\n",
    "    y_pred = np.array([round(x) for x in y_pred])\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    #Plotting confusion matrix using heatmap\n",
    "    fig, ax = plt.subplots(figsize = (8, 6))\n",
    "    ax = sns.heatmap(cm, annot=True, cmap='flare', fmt='g')\n",
    "\n",
    "    ax.set_title('Predictions for Pneumonia cases\\n\\n');\n",
    "    ax.set_xlabel('\\nPredicted Values')\n",
    "    ax.set_ylabel('Actual Values ');\n",
    "\n",
    "    ## Ticket labels - List must be in alphabetical order\n",
    "    ax.xaxis.set_ticklabels(['Normal','Pneumonia'])\n",
    "    ax.yaxis.set_ticklabels(['Normal','Pneumonia'])\n",
    "\n",
    "    ## Display the visualization of the Confusion Matrix.\n",
    "    plt.show();\n",
    "    \n",
    "    #Calculating normalization\n",
    "    row_sums = cm.sum(axis=1)\n",
    "    new_matrix = np.round(cm / row_sums[:, np.newaxis], 3)\n",
    "    \n",
    "    #Plotting confusion matrix using heatmap\n",
    "    fig, ax = plt.subplots(figsize = (8, 6))\n",
    "    ax = sns.heatmap(new_matrix, annot=True, cmap='flare', fmt='g')\n",
    "\n",
    "    ax.set_title('Predictions for Pneumonia cases\\n\\n')\n",
    "    ax.set_xlabel('\\nPredicted Values')\n",
    "    ax.set_ylabel('Actual Values ');\n",
    "\n",
    "    ## Ticket labels - List must be in alphabetical order\n",
    "    ax.xaxis.set_ticklabels(['Normal','Pneumonia'])\n",
    "    ax.yaxis.set_ticklabels(['Normal','Pneumonia'])\n",
    "\n",
    "    ## Display the visualization of the Confusion Matrix.\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making directories for train test and validation sets\n",
    "\n",
    "train_dir = \"data/chest_xray/chest_xray/train\"\n",
    "val_dir = \"data/chest_xray/chest_xray/val\"\n",
    "test_dir = \"data/chest_xray/chest_xray/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting value counts for each directory\n",
    "\n",
    "print('train_set:')\n",
    "print('---------')\n",
    "pneu_count_tr = len(os.listdir(os.path.join(train_dir, 'PNEUMONIA')))\n",
    "normal_count_tr = len(os.listdir(os.path.join(train_dir, 'NORMAL')))\n",
    "print(f'Pneumonia = {pneu_count_tr}')\n",
    "print(f'Normal = {normal_count_tr}')\n",
    "print('\\n')\n",
    "print('val_set:')\n",
    "print('---------')\n",
    "pneu_count_val = len(os.listdir(os.path.join(val_dir, 'PNEUMONIA')))\n",
    "normal_count_val = len(os.listdir(os.path.join(val_dir, 'NORMAL')))\n",
    "print(f'Pneumonia = {pneu_count_val}')\n",
    "print(f'Normal = {normal_count_val}')\n",
    "print('\\n')\n",
    "print('test_set:')\n",
    "print('---------')\n",
    "pneu_count_test = len(os.listdir(os.path.join(test_dir, 'PNEUMONIA')))\n",
    "normal_count_test = len(os.listdir(os.path.join(test_dir, 'NORMAL')))\n",
    "print(f'Pneumonia = {pneu_count_test}')\n",
    "print(f'Normal = {normal_count_test}')\n",
    "print('\\n') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's important to look at the counts of a dataset. Originally, this dataset had only 16 X-Ray images in the validation dataset, so 401 were moved from the train set to the validation set. Still, there are significantly more X-Ray images that show pneumonia than those that don't, which means that the classes need to be weighted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Displaying pneumonia X-rays\n",
    "pneumonia = os.listdir(\"data/chest_xray/chest_xray/train/PNEUMONIA\")\n",
    "pneumoniadir = \"data/chest_xray/chest_xray/train/PNEUMONIA\"\n",
    "\n",
    "\n",
    "# Plotting the X-rays\n",
    "plt.figure(figsize = (20, 10))\n",
    "for i in range(9):\n",
    "    plt.subplot(3, 3, i+1)\n",
    "    image = plt.imread(os.path.join(pneumoniadir, pneumonia[i]))\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Displaying normal X-rays\n",
    "normal = os.listdir(\"data/chest_xray/chest_xray/train/NORMAL\")\n",
    "normaldir = \"data/chest_xray/chest_xray/train/NORMAL\"\n",
    "\n",
    "plt.figure(figsize = (20, 10))\n",
    "for i in range(9):\n",
    "    plt.subplot(3, 3, i+1)\n",
    "    image = plt.imread(os.path.join(normaldir, normal[i]))\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the pneumonia images seem to be a little more hazy and less clear, but the X-Ray images are a little difficult to read. Though there aren't many untrained human eyes looking at the X-Rays, it can still be confusing for healthcare providers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the normal images\n",
    "\n",
    "normal_img = plt.imread(os.path.join(normaldir, normal[0]))\n",
    "normal_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the pneumonia images\n",
    "\n",
    "pneumonia_img = plt.imread(os.path.join(pneumoniadir, pneumonia[0]))\n",
    "pneumonia_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting a histogram of the pixels of the images\n",
    "\n",
    "sns.histplot(normal_img.ravel(), color = 'pink', bins = 150)\n",
    "plt.title('Pixel Intensity Distribution for a Normal X-Ray')\n",
    "plt.xlabel('Pixel Intensity')\n",
    "plt.ylabel('Number of pixels in the image')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting a histogram of the pixels of pneumonia images\n",
    "\n",
    "sns.histplot(pneumonia_img.ravel(), color = 'pink', bins = 150)\n",
    "plt.title('Pixel Intensity Distribution for a Pneumonia X-Ray')\n",
    "plt.xlabel('Pixel Intensity')\n",
    "plt.ylabel('Number of pixels in the image')\n",
    "sns.histplot(pneumonia_img.ravel(), color = 'pink', bins = 150);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating train and val datagen\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_dir, \n",
    "                                                    target_size=(224, 224), \n",
    "                                                    batch_size=32,\n",
    "                                                    class_mode='binary',\n",
    "                                                    shuffle = True)\n",
    "\n",
    "\n",
    "validation_generator = val_datagen.flow_from_directory(val_dir,\n",
    "                                                        target_size=(224, 224),\n",
    "                                                        batch_size=32,\n",
    "                                                        class_mode='binary',\n",
    "                                                        shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Checking available classes for the validation generator\n",
    "\n",
    "validation_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting class weights\n",
    "\n",
    "weight_pneu = pneu_count_tr / (pneu_count_tr + normal_count_tr)\n",
    "\n",
    "weight_normal = normal_count_tr / (pneu_count_tr + normal_count_tr)\n",
    "\n",
    "class_weight = {0 : weight_pneu, 1 : weight_normal}\n",
    "print(f'0 Weight Class = {weight_pneu}')\n",
    "print(f'1 Weight Class = {weight_normal}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initiating the model\n",
    "modelone = models.Sequential()\n",
    "\n",
    "# Input layer\n",
    "modelone.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
    "                        input_shape=(224, 224, 3)))\n",
    "modelone.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "#Hidden Layer\n",
    "modelone.add(layers.Flatten())\n",
    "modelone.add(layers.Dense(64, activation='relu'))\n",
    "\n",
    "#Output Layer\n",
    "modelone.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "modelone.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(learning_rate=1e-4),\n",
    "              metrics=tf.keras.metrics.BinaryAccuracy(name=\"binary_accuracy\", dtype=None, threshold=0.5)\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting summary for model one\n",
    "\n",
    "modelone.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the first model\n",
    "\n",
    "historyone = modelone.fit(train_generator, \n",
    "                              epochs=10, \n",
    "                              validation_data=validation_generator,\n",
    "                              class_weight = class_weight,\n",
    "                              steps_per_epoch = 100,\n",
    "                              validation_steps=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline Training Validation Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plotting history for model one\n",
    "\n",
    "plot_history(historyone)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this first baseline model, the first graph which plots training and validation accuracy. The model is fitting to the training set much better than the validation set. The validation accuracy line is muore jagged and inconsistent than the training set. When looking at loss, the training loss is more jagged and inconsistent, and the width between the two plots are more than I would hope."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Predictions Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calling pred_labels to see performance of model 1\n",
    "\n",
    "modelone_predsval = pred_labels(modelone, validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract predicted probabilities\n",
    "y_pred_probabilities = modelone_predsval[0]\n",
    "\n",
    "# Create an array of predicted labels based on a threshold (e.g., 0.5 for binary classification)\n",
    "threshold = 0.5\n",
    "y_pred = [1 if prob > threshold else 0 for prob in y_pred_probabilities]\n",
    "\n",
    "# Convert y_true to binary (assuming it's continuous or probabilities)\n",
    "y_true = [1 if label > 0.5 else 0 for label in modelone_predsval[1]]\n",
    "\n",
    "classification_rep = classification_report(y_true, y_pred, target_names=['Class 0', 'Class 1'])\n",
    "\n",
    "# Generate classification report\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the performance of model 1\n",
    "\n",
    "plot_roc_auc(modelone_predsval[0], modelone_predsval[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ROC curve above shows that the model learned incredibly fast with a true positive rate. The ROC curve peaks soon after some minor growth, but as time goes on, the false positive rate will continue to increase while the true positive plateaus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing confusion matrix for validation set\n",
    "\n",
    "conf_matrix(modelone_predsval[0], modelone_predsval[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This confusion matrix of the baseline model shows that there are 97.8% true positives, and 2.2% are false negatives, which represents the amount of patients not getting diagnosed. This is okay, but not reliable enough for this use case. Out of the patients with normal X-Ray images, 3.9% are false positives. It is better that the percentage of false positives is higher than the percentage of false negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the hparam variables\n",
    "\n",
    "HP_NUM_UNITS = hp.HParam('num_units', hp.Discrete([64, 128]))\n",
    "HP_DROPOUT = hp.HParam('dropout_rate', hp.RealInterval(0.1, 0.2))\n",
    "HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam', 'rmsprop']))\n",
    "HP_LEARNING_RATE = hp.HParam('learning_rate', hp.Discrete([0.01, 0.001, 0.0001]))\n",
    "METRIC_ACCURACY = 'binary_accuracy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a directory for logs\n",
    "\n",
    "logdir = 'logs/hparam_tuning'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a file writer for hyperparameter tuning\n",
    "\n",
    "with tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n",
    "  hp.hparams_config(\n",
    "    hparams=[HP_NUM_UNITS, HP_DROPOUT, HP_OPTIMIZER, HP_LEARNING_RATE],\n",
    "    metrics=[hp.Metric(METRIC_ACCURACY, display_name='binary_accuracy')],\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function below uses the baseline model as it's base model. It changes the nodes, optimizer, dropout and \n",
    "# learning rate based on the set params in the HParams. \n",
    "    \n",
    "# Creating function to do an HParams search\n",
    "def create_model_grid(hparams):\n",
    "    #Initializing model\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    #Adding CNN input layer\n",
    "    model.add(layers.Conv2D(32, (3,3), activation = 'relu', input_shape = (224, 224, 3)))\n",
    "    model.add(layers.MaxPooling2D(2,2))\n",
    "    model.add(layers.Dropout(hparams[HP_DROPOUT]))\n",
    "    \n",
    "    #Adding Dense hidden layer\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(hparams[HP_NUM_UNITS], activation = 'relu'))\n",
    "    model.add(layers.Dropout(hparams[HP_DROPOUT]))\n",
    "    \n",
    "    #Adding output layer\n",
    "    model.add(layers.Dense(1, activation = 'sigmoid'))\n",
    "    \n",
    "    #Looping through optimizers and learning rates\n",
    "    optimizer = hparams[HP_OPTIMIZER]\n",
    "    learning_rate = hparams[HP_LEARNING_RATE]\n",
    "    if optimizer == \"adam\":\n",
    "        optimizer = tf.optimizers.Adam(learning_rate=learning_rate)\n",
    "    elif optimizer=='rmsprop':\n",
    "        optimizer = tf.optimizers.RMSprop(learning_rate=learning_rate)\n",
    "    else:\n",
    "        raise ValueError(\"unexpected optimizer name: %r\" % (optimizer_name,))\n",
    "    \n",
    "    #Compiling model\n",
    "    model.compile(loss= 'binary_crossentropy', \n",
    "    optimizer= optimizer, \n",
    "    metrics= tf.keras.metrics.BinaryAccuracy(name=\"binary_accuracy\", dtype=None, threshold=0.5))\n",
    "    \n",
    "    #Fitting model\n",
    "    history=model.fit(\n",
    "    train_generator, #Using train data\n",
    "    steps_per_epoch=100, #Keeping 100 steps\n",
    "    epochs=10, #Keeping 10 epochs\n",
    "    validation_data=validation_generator, #Using validation data\n",
    "    class_weight = class_weight, #Adding weights to deal with imbalance\n",
    "    validation_steps=10, #Keeping 10 steps\n",
    "    )\n",
    "    \n",
    "    return history.history['val_binary_accuracy'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating run function\n",
    "\n",
    "def run(run_dir, hparams):\n",
    "  with tf.summary.create_file_writer(run_dir).as_default():\n",
    "    hp.hparams(hparams)  # record the values used in this trial\n",
    "    accuracy = create_model_grid(hparams)\n",
    "    tf.summary.scalar(METRIC_ACCURACY, accuracy, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Running hparams model\n",
    "\n",
    "session_num = 0\n",
    "\n",
    "for num_units in HP_NUM_UNITS.domain.values:\n",
    "  for dropout_rate in (HP_DROPOUT.domain.min_value, HP_DROPOUT.domain.max_value):\n",
    "    for optimizer in HP_OPTIMIZER.domain.values:\n",
    "        for learning_rate in HP_LEARNING_RATE.domain.values:\n",
    "            hparams = {\n",
    "              HP_NUM_UNITS: num_units,\n",
    "              HP_DROPOUT: dropout_rate,\n",
    "              HP_OPTIMIZER: optimizer,\n",
    "              HP_LEARNING_RATE: learning_rate\n",
    "              }\n",
    "            run_name = \"run-%d\" % session_num\n",
    "            print('--- Starting trial: %s' % run_name)\n",
    "            print({h.name: hparams[h] for h in hparams})\n",
    "            run('logs/hparam_tuning/' + run_name, hparams)\n",
    "            session_num += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here are some of the best parameters below.**\n",
    "\n",
    "run-4  \n",
    "{'num_units': 64, 'dropout_rate': 0.1, 'optimizer': 'rmsprop', 'learning_rate': 0.001}  \n",
    "84s 839ms/step - loss: 0.0478 - binary_accuracy: 0.9681 - val_loss: 0.1161 - val_binary_accuracy: 0.9625\n",
    "\n",
    "run-6  \n",
    "{'num_units': 64, 'dropout_rate': 0.2, 'optimizer': 'adam', 'learning_rate': 0.0001}  \n",
    "79s 790ms/step - loss: 0.0243 - binary_accuracy: 0.9759 - val_loss: 0.0816 - val_binary_accuracy: 0.9750\n",
    "\n",
    "run-21  \n",
    "{'num_units': 128, 'dropout_rate': 0.2, 'optimizer': 'rmsprop', 'learning_rate': 0.0001}  \n",
    "89s 889ms/step - loss: 0.0358 - binary_accuracy: 0.9625 - val_loss: 0.0964 - val_binary_accuracy: 0.9750"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best runs of the model are above. The best optimizer is adam, and the best dropout rate is 0.2. Run 6 is the best parameters out of the 3, because the binary accuracy is highest of 0.9759, and the binary accuracy of the validation set is *very* close at 0.9750. This means that the model is not overfitting, and is performing well with train *and* validation data. Now that we know which run has the best parameters, those parameters are what I will use to tune the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Tuning HParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Instantiating model 2\n",
    "\n",
    "model2 = models.Sequential()\n",
    "    \n",
    "#Adding CNN input layer\n",
    "model2.add(layers.Conv2D(32, (3,3), activation = 'relu', input_shape = (224, 224, 3)))\n",
    "model2.add(layers.MaxPooling2D(2,2))\n",
    "\n",
    "# Adding 0.2 to .Dropout since that was the best dropout parameter\n",
    "model2.add(layers.Dropout(0.2))\n",
    "    \n",
    "#Adding Dense hidden layer\n",
    "model2.add(layers.Flatten())\n",
    "\n",
    "# Adding best num_units to dense layer\n",
    "model2.add(layers.Dense(64, activation = 'relu'))\n",
    "model2.add(layers.Dropout(0.2))\n",
    "    \n",
    "#Adding output layer\n",
    "model2.add(layers.Dense(1, activation = 'sigmoid'))\n",
    "  \n",
    "#Looping through optimizers and learning rates\n",
    "\n",
    "#Compiling model\n",
    "model2.compile(loss= 'binary_crossentropy', \n",
    "optimizer= optimizers.Adam(lr = 1e-4), \n",
    "metrics= tf.keras.metrics.BinaryAccuracy(name=\"binary_accuracy\", dtype=None, threshold=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Printing the summary for model 2\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Fitting model 2\n",
    "\n",
    "history_hparams=model2.fit(\n",
    "train_generator, #Using train data\n",
    "steps_per_epoch=30, #Keeping 30 steps\n",
    "epochs=10, #Keeping 10 epochs\n",
    "validation_data=validation_generator, #Using validation data\n",
    "class_weight = class_weight, #Adding weights to deal with imbalance\n",
    "validation_steps=10, #Keeping 10 steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Calling the plot history function created earlier\n",
    "\n",
    "plot_history(history_hparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "With the graphs above of the accuracy and the loss function, the model typically wasn't running like this. I haven't ran it again, but I will continue to dry a different model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In the top graph above, the validation and training accuracy are plotted. The training accuracy curve is a much smoother curve than the validation curve, which means this second model is performing better on the validation set, but still not optimal performance. In the bottom graph that's above, the training loss and validation loss are plotted. The training loss shows how well the model is fitting the training data, and the validation loss shows how well the model fits new data. That being said, there is room to improve, so I'm going to check the predictions to determine next steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### HParams Predictions Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model2_predsval = pred_labels(model2, validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model2_predsval[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_roc_auc(model2_predsval[0], model2_predsval[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "I'm not quite sure what went wrong with this model, because previously it didn't run this way, but regardless, I'm going to continue trying different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "conf_matrix(model2_predsval[0], model2_predsval[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The confusion matrices above aren't showing the results we would like. False negatives and false positives seem to have switched places since the baseline model. 14.2% of patients with pneumonia are predicted to not have it, but the false positive rate is much lower than the. baseline at 0.5%. However, like I mentioned before, in healthcare cases, it's best to have more false positives than it is false negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Transfer Learning\n",
    "\n",
    "**Inception-V3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Instantiating model 3\n",
    "\n",
    "model3 = models.Sequential()\n",
    "\n",
    "# Creating an inception v3 model\n",
    "\n",
    "inception_v3 = tf.keras.applications.InceptionV3(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=(224, 224, 3),\n",
    "    classes=1\n",
    ")\n",
    "\n",
    "for layer in inception_v3.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model3.add(inception_v3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model3.add(layers.GlobalAveragePooling2D())\n",
    "model3.add(layers.Dense(64, activation = 'relu'))\n",
    "model3.add(layers.Dropout(0.2))\n",
    "\n",
    "#Adding output layer\n",
    "model3.add(layers.Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Compiling model\n",
    "model3.compile(loss= 'binary_crossentropy', \n",
    "optimizer= optimizers.Adam(lr = 1e-4), \n",
    "metrics= tf.keras.metrics.BinaryAccuracy(name=\"binary_accuracy\", dtype=None, threshold=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Fitting model 3\n",
    "\n",
    "history_transfer=model3.fit(\n",
    "train_generator, #Using train data\n",
    "steps_per_epoch=30, #Keeping 30 steps\n",
    "epochs=10, #Keeping 10 epochs\n",
    "validation_data=validation_generator, #Using validation data\n",
    "class_weight = class_weight, #Adding weights to deal with imbalance\n",
    "validation_steps=10, #Keeping 10 steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Calling the plot history function for the transfer tuning model\n",
    "\n",
    "plot_history(history_transfer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Transfer Learning Predictions Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model3_predsval = pred_labels(model3, validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_roc_auc(model3_predsval[0], model3_predsval[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This graph of the ROC/AUC curve shows a slightly different ROC curve than the previous models. The elbow doesn't occur quite as blatantly or as soon, but it does climb to a higher point than the previous models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "conf_matrix(model3_predsval[0], model3_predsval[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This confusion matrix shows better results than the second model, but still doesn't have as few false negatives as the baseline model. However, there is still a 95.1% true positive rate. Now, I'm going to tune the transfer learning model, just like I did with HParams."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Transfer Learning Tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Instantiating model 4\n",
    "\n",
    "model4 = models.Sequential()\n",
    "\n",
    "inception_v3_tuned = tf.keras.applications.InceptionV3(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=(224, 224, 3),\n",
    "    classes=1\n",
    ")\n",
    "\n",
    "\n",
    "for layer in inception_v3_tuned.layers[:-31]:\n",
    "    layer.trainable = False\n",
    "\n",
    "for i, layer in enumerate(inception_v3_tuned.layers):\n",
    "    print(i, layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Input Layer\n",
    "\n",
    "model4.add(inception_v3_tuned)\n",
    "\n",
    "# Hidden Layer\n",
    "model4.add(layers.GlobalAveragePooling2D())\n",
    "model4.add(layers.Dense(64, activation = 'relu'))\n",
    "model4.add(layers.Dropout(0.2))\n",
    "\n",
    "#Adding output layer\n",
    "model4.add(layers.Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Compiling model\n",
    "model4.compile(loss= 'binary_crossentropy', \n",
    "optimizer= optimizers.Adam(lr = 1e-4), \n",
    "metrics= tf.keras.metrics.BinaryAccuracy(name=\"binary_accuracy\", dtype=None, threshold=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Printing the summary for model 4\n",
    "\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Fitting model\n",
    "\n",
    "history_transfertune=model4.fit(\n",
    "train_generator, #Using train data\n",
    "steps_per_epoch=30, #Keeping 30 steps\n",
    "epochs=10, #Keeping 10 epochs\n",
    "validation_data=validation_generator, #Using validation data\n",
    "class_weight = class_weight, #Adding weights to deal with imbalance\n",
    "validation_steps=10, #Keeping 10 steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Plotting history for model one\n",
    "\n",
    "plot_history(history_transfertune)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Transfer Learning Predictions Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Calling pred_labels on model 4\n",
    "\n",
    "model4_predsval = pred_labels(model4, validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Plotting the rocauc curbes with a function\n",
    "\n",
    "plot_roc_auc(model4_predsval[0], model4_predsval[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This ROC/AUC curve shows one of the best ROC curves that I've achieved so far, with a 99.6% AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Calling the confusion matrix function\n",
    "\n",
    "conf_matrix(model4_predsval[0], model4_predsval[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The false negative rate in this confusion matrix for the tuned transfer learning model is 1.7%. The false positive rate is 5.6%, so still higher than the false negatives (which is good). The true positive rate is 98.3%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model4.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_directory(test_dir,\n",
    "                                                        target_size=(224, 224),\n",
    "                                                        batch_size=32,\n",
    "                                                        class_mode='binary',\n",
    "                                                        shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_preds = pred_labels(model4, test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "conf_matrix(final_preds[0], final_preds[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After iterating through different types of possible models, the best model was Inception V3 tuned (model 4). I decided to use that model to test the test set. The model performed well on the train set and had a 99.2% true positive rate, and a .8% false negative rate. This is a result that I am happy with endorsing as using for a second opinion, or a tool to help flag pneumonia and diagnose patients faster. The AUC line had a score of 0.994. The AUC line measures the ability of the model to distinguish between classes, which is something I am satisfied with. The last epoch of the fourth model has a binary accuracy score of 0.9812, with a validation binary accuracy score of 0.9688. Although the binary accuracy score and the validation binary accuracy score could be closer together, that is still a good performance on the validation set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some recommendatios I would make based on this notebook would be to use **Inception V3** as a model. In addition, there are actually several types of pneumonia. This notebook is only testing for whether or not pneumonia is present, but with more layers, different types of pneumonia could be classified as well. The reason neural networks were used for this, is because images are 3-dimensional, so they require models that are more complex. Since there isn't patient data, I'm not able to measure how diverse the demographics are, but I would recommend those be included in order to make sure the model is being trained on all ages, sexes, ethnicities, and backgrounds."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
